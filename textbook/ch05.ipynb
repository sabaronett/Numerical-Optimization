{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 First-Order Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type DescentMethod end\n",
    "\n",
    "struct GradientDescent <: DescentMethod\n",
    "    α\n",
    "end\n",
    "init!(M::GradientDescent, f, ∇f, x) = M\n",
    "function step!(M::GradientDescent, f, ∇f, x)\n",
    "    α, g = M.α, ∇f(x)\n",
    "    return x - α*g\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Conjugate Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ConjugateGradientDescent <: DescentMethod\n",
    "    d\n",
    "    g\n",
    "end\n",
    "function init!(M::ConjugateGradientDescent, f, ∇f, x)\n",
    "    M.g = ∇f(x)\n",
    "    M.d = -M.g\n",
    "    return M\n",
    "end\n",
    "function step!(M::ConjugateGradientDescent, f, ∇f, x)\n",
    "    d, g = M.d, M.g\n",
    "    g′ = ∇f(x)\n",
    "    β = max(0, dot(g′, g′-g)/(g⋅g))\n",
    "    d′ = -g′ + β*d\n",
    "    x′ = line_search(f, x, d′)\n",
    "    M.d, M.g = d′, g′\n",
    "    return x′\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Momentum <: DescentMethod\n",
    "    α # learning rate\n",
    "    β # momentum decay\n",
    "    v # momentum\n",
    "end\n",
    "function init!(M::Momentum, f, ∇f, x)\n",
    "    M.v = zeros(length(x))\n",
    "    return M\n",
    "end\n",
    "function step!(M::Momentum, f, ∇f, x)\n",
    "    α, β, v, g = M.α, M.β, M.v, ∇f(x)\n",
    "    v[:] = β*v - α*g\n",
    "    return x + v\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Nesterov Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct NesterovMomentum <: DescentMethod\n",
    "    α # learning rate\n",
    "    β # momentum decay\n",
    "    v # momentum\n",
    "end\n",
    "function init!(M::NesterovMomentum, f, ∇f, x)\n",
    "    M.v = zeros(length(x))\n",
    "    return M\n",
    "end\n",
    "function step!(M::NesterovMomentum, f, ∇f, x)\n",
    "    α, β, v = M.α, M.β, M.v\n",
    "    v[:] = β*v - α*∇f(x + β*v)\n",
    "    return x + v\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Adagrad <: DescentMethod\n",
    "    α # learning rate\n",
    "    ϵ # small value\n",
    "    s # sum of squared gradient\n",
    "end\n",
    "function init!(M::Adagrad, f, ∇f, x)\n",
    "    M.s = zeros(length(x))\n",
    "    return M\n",
    "end\n",
    "function step!(M::Adagrad, f, ∇f, x)\n",
    "    α, ϵ, s, g = M.α, M.ϵ, M.s, ∇f(x)\n",
    "    s[:] += g.*g\n",
    "    return x - α*g ./ (sqrt.(s) .+ ϵ)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct RMSProp <: DescentMethod\n",
    "    α # learning rate\n",
    "    γ # decay\n",
    "    ϵ # small value\n",
    "    s # sum of squared gradient\n",
    "end\n",
    "function init!(M::RMSProp, f, ∇f, x)\n",
    "    M.s = zeros(length(x))\n",
    "    return M\n",
    "end\n",
    "function step!(M::RMSProp, f, ∇f, x)\n",
    "    α, γ, ϵ, s, g = M.α, M.γ, M.ϵ, M.s, ∇f(x)\n",
    "    s[:] = γ*s + (1-γ)*(g.*g)\n",
    "    return x - α*g ./ (sqrt.(s) .+ ϵ)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Adadelta <: DescentMethod\n",
    "    γs # gradient decay\n",
    "    γx # update decay\n",
    "    ϵ # small value\n",
    "    s # sum of squared gradients\n",
    "    u # sum of squared updates\n",
    "end\n",
    "function init!(M::Adadelta, f, ∇f, x)\n",
    "    M.s = zeros(length(x))\n",
    "    M.u = zeros(length(x))\n",
    "    return M\n",
    "end\n",
    "function step!(M::Adadelta, f, ∇f, x)\n",
    "    γs, γx, ϵ, s, u, g = M.γs, M.γx, M.ϵ, M.s, M.u, ∇f(x)\n",
    "    s[:] = γs*s + (1-γs)*g.*g\n",
    "    Δx = - (sqrt.(u) .+ ϵ) ./ (sqrt.(s) .+ ϵ) .* g\n",
    "    u[:] = γx*u + (1-γx)*Δx.*Δx\n",
    "    return x + Δx\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Adam <: DescentMethod\n",
    "    α # learning rate\n",
    "    γv # decay\n",
    "    γs # decay\n",
    "    ϵ # small value\n",
    "    k # step counter\n",
    "    v # 1st moment estimate\n",
    "    s # 2nd moment estimate\n",
    "end\n",
    "function init!(M::Adam, f, ∇f, x)\n",
    "    M.k = 0\n",
    "    M.v = zeros(length(x))\n",
    "    M.s = zeros(length(x))\n",
    "    return M\n",
    "end\n",
    "function step!(M::Adam, f, ∇f, x)\n",
    "    α, γv, γs, ϵ, k = M.α, M.γv, M.γs, M.ϵ, M.k\n",
    "    s, v, g = M.s, M.v, ∇f(x)\n",
    "    v[:] = γv*v + (1-γv)*g\n",
    "    s[:] = γs*s + (1-γs)*g.*g\n",
    "    M.k = k += 1\n",
    "    v_hat = v ./ (1 - γv^k)\n",
    "    s_hat = s ./ (1 - γs^k)\n",
    "    return x - α*v_hat ./ (sqrt.(s_hat) .+ ϵ)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Hypergradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct HyperGradientDescent <: DescentMethod\n",
    "    α0 # initial learning rate\n",
    "    μ # learning rate of the learning rate\n",
    "    α # current learning rate\n",
    "    g_prev # previous gradient\n",
    "end\n",
    "function init!(M::HyperGradientDescent, f, ∇f, x)\n",
    "    M.α = M.α0\n",
    "    M.g_prev = zeros(length(x))\n",
    "    return M\n",
    "end\n",
    "function step!(M::HyperGradientDescent, f, ∇f, x)\n",
    "    α, μ, g, g_prev = M.α, M.μ, ∇f(x), M.g_prev\n",
    "    α = α + μ*(g⋅g_prev)\n",
    "    M.g_prev, M.α = g, α\n",
    "    return x - α*g\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct HyperNesterovMomentum <: DescentMethod\n",
    "    α0 # initial learning rate\n",
    "    μ # learning rate of the learning rate\n",
    "    β # momentum decay\n",
    "    v # momentum\n",
    "    α # current learning rate\n",
    "    g_prev # previous gradient\n",
    "end\n",
    "function init!(M::HyperNesterovMomentum, f, ∇f, x)\n",
    "    M.α = M.α0\n",
    "    M.v = zeros(length(x))\n",
    "    M.g_prev = zeros(length(x))\n",
    "    return M\n",
    "end\n",
    "function step!(M::HyperNesterovMomentum, f, ∇f, x)\n",
    "    α, β, μ = M.α, M.β, M.μ\n",
    "    v, g, g_prev = M.v, ∇f(x), M.g_prev\n",
    "    α = α - μ*(g⋅(-g_prev - β*v))\n",
    "    v[:] = β*v + g\n",
    "    M.g_prev, M.α = g, α\n",
    "    return x - α*(g + β*v)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
